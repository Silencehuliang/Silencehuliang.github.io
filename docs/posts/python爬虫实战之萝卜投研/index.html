<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Python爬虫实战之萝卜投研 - Silence Blog</title><meta name="Description" content="Python爬虫实战之萝卜投研"><meta property="og:title" content="Python爬虫实战之萝卜投研" />
<meta property="og:description" content="Python爬虫实战之萝卜投研" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://49.235.231.121/posts/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8B%E8%90%9D%E5%8D%9C%E6%8A%95%E7%A0%94/" />
<meta property="article:published_time" content="2020-02-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-02-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Python爬虫实战之萝卜投研"/>
<meta name="twitter:description" content="Python爬虫实战之萝卜投研"/>
<meta name="application-name" content="Silence Blog">
<meta name="apple-mobile-web-app-title" content="Silence Blog"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://49.235.231.121/posts/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8B%E8%90%9D%E5%8D%9C%E6%8A%95%E7%A0%94/" /><link rel="prev" href="http://49.235.231.121/posts/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8B%E5%8F%A9%E5%AF%8C%E7%BD%91/" /><link rel="next" href="http://49.235.231.121/posts/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8Bbilibili/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Python爬虫实战之萝卜投研",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/49.235.231.121\/posts\/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8B%E8%90%9D%E5%8D%9C%E6%8A%95%E7%A0%94\/"
        },"genre": "posts","keywords": "爬虫, 实战","wordcount":  2807 ,
        "url": "http:\/\/49.235.231.121\/posts\/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8B%E8%90%9D%E5%8D%9C%E6%8A%95%E7%A0%94\/","datePublished": "2020-02-28T00:00:00+00:00","dateModified": "2021-02-20T00:00:00+00:00","publisher": {
            "@type": "Organization",
            "name": "作者"},"author": {
                "@type": "Person",
                "name": "作者"
            },"description": "Python爬虫实战之萝卜投研"
    }
    </script></head>
    <body header-desktop="" header-mobile=""><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : '' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Silence Blog">Silence Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Silence Blog">Silence Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Python爬虫实战之萝卜投研</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>作者</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E7%88%AC%E8%99%AB/"><i class="far fa-folder fa-fw"></i>爬虫</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-02-28">2020-02-28</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 2807 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#爬虫介绍">爬虫介绍</a>
      <ul>
        <li><a href="#网站介绍">网站介绍</a></li>
        <li><a href="#编写爬虫的原因和用途">编写爬虫的原因和用途</a></li>
      </ul>
    </li>
    <li><a href="#scrapy">Scrapy</a>
      <ul>
        <li><a href="#简介">简介</a></li>
        <li><a href="#使用教程">使用教程</a></li>
      </ul>
    </li>
    <li><a href="#抓包工具">抓包工具</a>
      <ul>
        <li><a href="#什么是抓包工具">什么是抓包工具</a></li>
        <li><a href="#为什么要用">为什么要用</a></li>
        <li><a href="#使用与抓包工具的推荐">使用与抓包工具的推荐</a></li>
      </ul>
    </li>
    <li><a href="#业务逻辑分析">业务逻辑分析</a>
      <ul>
        <li><a href="#寻找加载数据的url">寻找加载数据的URL</a></li>
        <li><a href="#翻页参数解析">翻页参数解析</a></li>
      </ul>
    </li>
    <li><a href="#模拟请求测试">模拟请求测试</a>
      <ul>
        <li><a href="#scrapy-shell">scrapy shell</a></li>
        <li><a href="#postman">Postman</a></li>
      </ul>
    </li>
    <li><a href="#编写爬虫">编写爬虫</a>
      <ul>
        <li><a href="#创建爬虫项目">创建爬虫项目</a></li>
        <li><a href="#robots协议">robots协议</a></li>
        <li><a href="#创建爬虫">创建爬虫</a></li>
        <li><a href="#修改start_urls">修改start_urls</a></li>
        <li><a href="#完成parse方法">完成parse方法</a></li>
        <li><a href="#完成数据存储">完成数据存储</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p><strong>声明：以下内容均为我个人的理解，如果发现错误或者疑问可以联系我共同探讨</strong></p>
<h2 id="爬虫介绍">爬虫介绍</h2>
<h3 id="网站介绍">网站介绍</h3>
<p>本次要爬取的网站为*<a href="https://robo.datayes.com/" target="_blank" rel="noopener noreffer">萝卜投研</a>*，是利用人工智能、大数据、移动应用技术,建立的股票基本面分析智能投研平台，在进行投资交易的时候可以使用期研报与各类数据进行分析。</p>
<h3 id="编写爬虫的原因和用途">编写爬虫的原因和用途</h3>
<p>本人闲暇时间会学习投资理财相关内容，萝卜投研可以获取许多财经类的信息与很多研报，本次想通过编写爬虫完成对目标数据完成持久化存储与相关舆情完成程序提醒的目标，由于网站内容十分丰富，一次很难将其全部爬取完毕，本次想通过Scrapy获取首页的投研信息，并完成翻页的目标，后期还会持续更新，尝试将整个网站都爬下来。（仅供个人研究使用）</p>
<h2 id="scrapy">Scrapy</h2>
<h3 id="简介">简介</h3>
<p><a href="https://scrapy.org/" target="_blank" rel="noopener noreffer">Scrapy</a>是一个为了爬取网站数据，提取结构性数据编写的爬虫框架，只需要很少的代码就可以完成相关数据的抓取。</p>
<p>Scrapy是一个使用了Twisted的异步网络框架，可以大大提高我们的下载速度。</p>
<h3 id="使用教程">使用教程</h3>
<p>Scrapy的相关使用教程可以通过<a href="https://docs.scrapy.org/en/latest/" target="_blank" rel="noopener noreffer">官方文档</a>来进行初步入门，了解各模块在框架中的作用，官方文档非常强大，建议先进行系统性的学习之后再开始使用。</p>
<p>学习Scrapy最重要的就是理解Scrapy的工作流程，跟着<a href="https://docs.scrapy.org/en/latest/intro/tutorial.html" target="_blank" rel="noopener noreffer">官方文档的例子</a>去详细分析每一步的操作，与之前编写爬虫的流程相关性与区别。</p>
<h2 id="抓包工具">抓包工具</h2>
<h3 id="什么是抓包工具">什么是抓包工具</h3>
<p>抓包工具是拦截查看网络数据包内容的软件。通过对抓获的数据包进行分析，可以得到有用的信息。</p>
<h3 id="为什么要用">为什么要用</h3>
<p>较为复杂的网站在进行爬取数据分析的时候使用浏览器中的调试工具会比较麻烦，这时候就可以用抓包工具去分析对应的请求，从而更快发现我们需要的数据所在的URL和整个请求的过程</p>
<h3 id="使用与抓包工具的推荐">使用与抓包工具的推荐</h3>
<p>抓包工具的使用推荐学习<a href="https://www.axihe.com/" target="_blank" rel="noopener noreffer">朱安邦的博客</a>中的教程，他讲了三个：Charles、Fiddler、wireshark，这些抓包工具功能各异，但基本原理相同，找一个顺手的学习基本上已经足够了。</p>
<h2 id="业务逻辑分析">业务逻辑分析</h2>
<h3 id="寻找加载数据的url">寻找加载数据的URL</h3>
<p>通过对整个首页加载的流程进行抓包与分析，发现首页数据的URL为<code>https://gw.datayes.com/rrp_mammon/web/feed/list</code>，下一页的URL为：<code>https://gw.datayes.com/rrp_mammon/web/feed/list?timeStamp=20210401170127&amp;feedIds=66233,66148</code>，</p>
<h3 id="翻页参数解析">翻页参数解析</h3>
<p>通过观察URL发现timeStamp和feedIds是两个控制翻页的参数，进一步多页进行请求发现20210401170127可以理解为一个时间节点，看到20200228猜测是本次刷新的时间，猜测后6位是当前时间的秒的时间戳，组织一下可以写成<code>''.join(str(datetime.now())[:10].split('-'))+str(time.clock( )).split('.')[1]</code></p>
<p>再进行多页的数据获取后发现feedIds参数中的前四个是第一个响应中前四个数据的id，最后一个数为响应中最后一个数据的id，并且会随着访问变多而增加，每次新增的都是最后一个数据的id，将下一页的URL拼接起来,进行访问发现请求不到下一页的数据。通过复制原来的timeStamp发现可以访问，问题就出现在前面timeStamp的参数，刚刚再进行feedIds字段拼接的时候发现有三个字段是日期形式的，分别为：<code>&quot;insertTime&quot;</code>、<code>updateTime</code>、<code>publishTime</code>，进一步分析发现将其后面三个0去掉就是一个时间戳，对其转换发现就是我们需要的结果</p>
<h2 id="模拟请求测试">模拟请求测试</h2>
<h3 id="scrapy-shell">scrapy shell</h3>
<p>scrapy shell可以帮助我们模拟请求地址，并进入一个交互式终端，在交互式终端中我们可以查看请求的各类信息，并进行调试。但scrapy shell也有缺陷，不能解析response的格式，看起来比较乱等，这时候可以通过结合Postman来协同调试。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://tvax3.sinaimg.cn/large/00729CCqgy1gp5ct1yz35j31fg0qdhan.jpg"
        data-srcset="https://tvax3.sinaimg.cn/large/00729CCqgy1gp5ct1yz35j31fg0qdhan.jpg, https://tvax3.sinaimg.cn/large/00729CCqgy1gp5ct1yz35j31fg0qdhan.jpg 1.5x, https://tvax3.sinaimg.cn/large/00729CCqgy1gp5ct1yz35j31fg0qdhan.jpg 2x"
        data-sizes="auto"
        alt="https://tvax3.sinaimg.cn/large/00729CCqgy1gp5ct1yz35j31fg0qdhan.jpg"
        title="https://tvax3.sinaimg.cn/large/00729CCqgy1gp5ct1yz35j31fg0qdhan.jpg" /></p>
<h3 id="postman">Postman</h3>
<h4 id="简介-1">简介</h4>
<p><a href="https://www.postman.com/" target="_blank" rel="noopener noreffer">Postman</a>是一种网页调试与发送网页http请求的chrome插件。我们可以用来很方便的模拟各种类型的请求来调试 接口。在爬虫中可以用于验证我们的思路。</p>
<h4 id="使用与汉化">使用与汉化</h4>
<p>Postman官方的使用教程非常详细，可以跟着官方的使用教程中学习，如果想使用中文的版本可以在<a href="https://gitee.com/hlmd/PostmanCn" target="_blank" rel="noopener noreffer">Postman汉化</a>中下载。</p>
<h4 id="实际使用">实际使用</h4>
<p>通过Postman发送请求，可以得到我们想要的数据，并且可以得到格式化后的数据，看起来条理更加清晰，再配合scrapy shell调试可以很容易就获得我们需要的数据</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://tva3.sinaimg.cn/large/00729CCqgy1gp56fudgzoj312o0pctjb.jpg"
        data-srcset="https://tva3.sinaimg.cn/large/00729CCqgy1gp56fudgzoj312o0pctjb.jpg, https://tva3.sinaimg.cn/large/00729CCqgy1gp56fudgzoj312o0pctjb.jpg 1.5x, https://tva3.sinaimg.cn/large/00729CCqgy1gp56fudgzoj312o0pctjb.jpg 2x"
        data-sizes="auto"
        alt="https://tva3.sinaimg.cn/large/00729CCqgy1gp56fudgzoj312o0pctjb.jpg"
        title="https://tva3.sinaimg.cn/large/00729CCqgy1gp56fudgzoj312o0pctjb.jpg" /></p>
<h2 id="编写爬虫">编写爬虫</h2>
<h3 id="创建爬虫项目">创建爬虫项目</h3>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">scrapy startproject datayes
</code></pre></div><h3 id="robots协议">robots协议</h3>
<p>在settings.py中可以通过设置<code>ROBOTSTXT_OBEY = True</code>遵守robots.txt 的规则。</p>
<h3 id="创建爬虫">创建爬虫</h3>
<pre><code>scrapy genspider mammon gw.datayes.com
</code></pre><h3 id="修改start_urls">修改start_urls</h3>
<p>默认的start_urls不是我们要爬取的链接，修改为我们需求的链接</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://gw.datayes.com/rrp_mammon/web/feed/list&#39;</span><span class="p">]</span>
</code></pre></div><h3 id="完成parse方法">完成parse方法</h3>
<p>根据之前分析的结果设计方案完成parse，这次难度主要在于如何拼接next_url，由于feedIds参数存在着累加的关系所以将其放在了parse函数外让其可以再访问的时候累加处理。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">MammonSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;mammon&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;gw.datayes.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://gw.datayes.com/rrp_mammon/web/feed/list&#39;</span><span class="p">]</span>
    <span class="c1"># 构建一个基础next_url</span>
    <span class="n">next_url</span> <span class="o">=</span> <span class="s1">&#39;https://gw.datayes.com/rrp_mammon/web/feed/list?timeStamp=&#39;</span>
    <span class="c1"># 构建一个基础feedIds</span>
    <span class="n">feedIds</span> <span class="o">=</span> <span class="s1">&#39;&amp;feedIds=&#39;</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1"># 将获取到的数据通过json转成字典的形式</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="c1"># 当访问成功时进行数据获取</span>
        <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;success&#39;</span><span class="p">:</span>
            <span class="n">data_list</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;list&#39;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">:</span>
                <span class="n">item</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">detail_id</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>  <span class="c1"># id</span>
                <span class="c1"># 通过详情页id构造详情页url并访问</span>
                <span class="n">detail_url</span> <span class="o">=</span> <span class="s1">&#39;https://gw.datayes.com/rrp_mammon/web/feed?id=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">detail_id</span><span class="p">)</span>
                <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">detail_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">detail_parse</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="n">item</span><span class="p">})</span>

                <span class="n">item</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span>  <span class="c1"># 标题</span>
                <span class="n">item</span><span class="p">[</span><span class="s1">&#39;publish_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;publishTime&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>  <span class="c1"># 发布时间</span>
                <span class="n">item</span><span class="p">[</span><span class="s1">&#39;author&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;roboColumn&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>  <span class="c1"># 作者</span>
                <span class="n">item</span><span class="p">[</span><span class="s1">&#39;Avatar&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;roboColumn&#39;</span><span class="p">][</span><span class="s1">&#39;logo&#39;</span><span class="p">]</span>  <span class="c1"># 头像</span>
                <span class="n">related_list</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;related&#39;</span><span class="p">]</span>
                <span class="n">item</span><span class="p">[</span><span class="s1">&#39;related_stocks&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 相关股票列表</span>
                <span class="k">for</span> <span class="n">stocks</span> <span class="ow">in</span> <span class="n">related_list</span><span class="p">:</span>
                    <span class="n">item</span><span class="p">[</span><span class="s1">&#39;related_stocks&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stocks</span><span class="p">[</span><span class="s1">&#39;targetName&#39;</span><span class="p">])</span>

                <span class="c1"># 寻找出url的第0，1，2，3位置的id，加入feedIds</span>
                <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">url</span> <span class="o">==</span> <span class="s1">&#39;https://gw.datayes.com/rrp_mammon/web/feed/list&#39;</span> <span class="ow">and</span> <span class="n">data_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">feedIds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedIds</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">detail_id</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span>
            <span class="c1"># 构建timeStamp参数</span>
            <span class="n">timeStamp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&#34;%Y%m</span><span class="si">%d</span><span class="s2">%H%M%S&#34;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">localtime</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;publish_time&#39;</span><span class="p">]))</span>
            <span class="c1"># 拼接feedIds参数</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feedIds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedIds</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">detail_id</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span>
            <span class="c1"># 组合next_url</span>
            <span class="n">next_url</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_url</span> <span class="o">+</span> <span class="n">timeStamp</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedIds</span>
            <span class="c1"># 请求下一页</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">detail_parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;success&#39;</span><span class="p">:</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span>
            <span class="n">item</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;longDocContent&#39;</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">item</span>
</code></pre></div><p>通过爬虫观察到两日的cookie发生了变化，只有登录之后会保持cookie，并对cookie中的参数进行检测，找到<code>cloud-sso-token</code>为必要参数，并将其添加在settings.py中。</p>
<h3 id="完成数据存储">完成数据存储</h3>
<p>先在settings.py中配置pipeline，和数据库相关参数</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Configure item pipelines</span>
<span class="c1"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;datayes.pipelines.DatayesPipeline&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
<span class="p">}</span>
<span class="c1"># MySQL相关配置</span>
<span class="n">HOST</span> <span class="o">=</span> <span class="s1">&#39;HOST&#39;</span><span class="p">,</span>  <span class="c1"># 数据库地址</span>
<span class="n">PORT</span> <span class="o">=</span> <span class="mi">3306</span><span class="p">,</span>  <span class="c1"># 数据库端口</span>
<span class="n">DB</span> <span class="o">=</span> <span class="s1">&#39;DB&#39;</span><span class="p">,</span>  <span class="c1"># 数据库名</span>
<span class="n">USER</span> <span class="o">=</span> <span class="s1">&#39;USER&#39;</span><span class="p">,</span>  <span class="c1"># 数据库用户名</span>
<span class="n">PASSWORD</span> <span class="o">=</span> <span class="s1">&#39;PASSWORD&#39;</span><span class="p">,</span>  <span class="c1"># 数据库密码</span>
</code></pre></div><p>在我们定义的DatayesPipeline类中添加open_spider和close_spider方法，通过spider.settings来导入数据库相关参数</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pymysql</span>


<span class="k">class</span> <span class="nc">DatayesPipeline</span><span class="p">:</span>
    <span class="c1"># 爬虫开始时执行，只执行一次</span>
    <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="c1"># 通过pymysql链接MySQL数据库</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connect</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
            <span class="n">host</span><span class="o">=</span><span class="n">spider</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">HOST</span><span class="p">,</span>  <span class="c1"># 数据库地址</span>
            <span class="n">port</span><span class="o">=</span><span class="n">spider</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">PORT</span><span class="p">,</span>  <span class="c1"># 数据库端口</span>
            <span class="n">db</span><span class="o">=</span><span class="n">spider</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">DB</span><span class="p">,</span>  <span class="c1"># 数据库名</span>
            <span class="n">user</span><span class="o">=</span><span class="n">spider</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">USER</span><span class="p">,</span>  <span class="c1"># 数据库用户名</span>
            <span class="n">passwd</span><span class="o">=</span><span class="n">spider</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">PASSWORD</span><span class="p">,</span>  <span class="c1"># 数据库密码</span>
            <span class="n">charset</span><span class="o">=</span><span class="s1">&#39;utf8&#39;</span><span class="p">,</span>  <span class="c1"># 编码方式</span>
            <span class="n">use_unicode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c1"># 通过cursor执行增删查改</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cursor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

    <span class="c1"># 爬虫结束时执行，只执行一次</span>
    <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="s2">&#34;&#34;&#34;insert into mammon (title, publish_time,author,avatar,related_stocks,content)value (</span><span class="si">%s</span><span class="s2">, </span><span class="si">%s</span><span class="s2">,</span><span class="si">%s</span><span class="s2">, </span><span class="si">%s</span><span class="s2">,</span><span class="si">%s</span><span class="s2">, </span><span class="si">%s</span><span class="s2">)&#34;&#34;&#34;</span><span class="p">,</span>
            <span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;publish_time&#39;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;author&#39;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;avatar&#39;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;related_stocks&#39;</span><span class="p">],</span>
             <span class="n">item</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]))</span>
        <span class="c1"># 提交sql语句</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</code></pre></div><p>最后创建数据库，开启爬虫进行数据爬取。</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2021-02-20</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a>,&nbsp;<a href="/tags/%E5%AE%9E%E6%88%98/">实战</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8B%E5%8F%A9%E5%AF%8C%E7%BD%91/" class="prev" rel="prev" title="Python爬虫实战之叩富网"><i class="fas fa-angle-left fa-fw"></i>Python爬虫实战之叩富网</a>
            <a href="/posts/python%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E4%B9%8Bbilibili/" class="next" rel="next" title="Python爬虫实战之bilibili">Python爬虫实战之bilibili<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.74.3">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
