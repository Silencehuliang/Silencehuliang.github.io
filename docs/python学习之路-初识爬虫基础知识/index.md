# Python学习之路-初识爬虫:基础知识


## 什么是爬虫

网络爬虫（又被称为网页蜘蛛，网络机器人）就是模拟客户端发送网络请求，接收请求响应，一种按照一定的规则，自动地抓取互联网信息的程序。

原则上,只要是浏览器(客户端)能做的事情，爬虫都能够做

## 用途

如今，人工智能，大数据离我们越来越近，很多公司在开展相关的业务，但是人工智能和大数据中有一个东西非常重要，那就是数据，但是数据从哪里来呢？这时候爬虫的用途就凸显出来了，他可以做到以下几个方面

- 进行在网页或者是app上进行展示
- 进行数据分析或者是机器学习相关的项目
- 12306抢票
- 商品价格历史记录

不仅仅是以上用途，爬虫用途非常广泛。

## 分类

根据被爬网站的数量的不同，我们把爬虫分为：

- 通用爬虫 ：通常指搜索引擎的爬虫
- 聚焦爬虫 ：针对特定网站的爬虫

## 流程

### 聚焦爬虫

一般情况下我们会通过一个起始URL去获取到响应内容，根据响应内容提取我们需要的数据与需要爬取的URL，数据可以入库保存，提取到的URL进行进一步爬取。

### 通用爬虫

搜索引擎爬虫会通过抓取网页将获取到的数据存储，并进行预处理，然后对外提供检索服务，并对抓取到的网页进行排名。

### 搜索引擎的局限性

- 通用搜索引擎所返回的网页里90%的内容无用。
- 图片、音频、视频多媒体的内容通用搜索引擎无能为力
- 不同用户搜索的目的不全相同，但是返回内容相同

## robots协议

Robots协议：网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取，但它仅仅是道德层面上的约束

## 浏览器发送HTTP请求的过程

浏览器会主动请求js，css等内容，js会修改页面的内容，js也可以重新发送请求，最后浏览器渲染出来的内容在elements中，其中包含css，图片，js，url地址对应的响应等。

但是在爬虫中，爬虫只会请求url地址，对应的拿到url地址对应的响应

浏览器渲染出来的页面和爬虫请求的页面并不一样

**所以在爬虫中，需要以url地址对应的响应为准来进行数据的提取**

## url的形式

url的形式：scheme://host[:port#]/path/…/[?query-string][#anchor]

- scheme：协议(例如：http, https, ftp)
- host：服务器的IP地址或者域名
- port：服务器的端口（如果是走协议默认端口，80 or 443）
- path：访问资源的路径
- query-string：参数，发送给http服务器的数据
- anchor：锚（跳转到网页的指定锚点位置）
  - http://localhost:4000/file/part01/1.2.html
  - **url地址中是否包含锚点对响应没有影响**

## HTTP常见请求头

1. Host (主机和端口号)
2. Connection (链接类型)
3. Upgrade-Insecure-Requests (升级为HTTPS请求)
4. User-Agent (浏览器名称)
5. Accept (传输文件类型)
6. Referer (页面跳转处)
7. Accept-Encoding（文件编解码格式）
8. Cookie （Cookie）
9. x-requested-with :XMLHttpRequest (是Ajax 异步请求)

## 响应状态码(status code)

常见的状态码：

- 200：成功
- 302：临时转移至新的url
- 307：临时转移至新的url
- 404：not found
- 500：服务器内部错误


